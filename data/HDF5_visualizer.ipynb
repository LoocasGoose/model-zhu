{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization for MediumImageNet Dataset\n",
    "A simple visualizer to display examples from the MediumImageNet dataset along with their class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names file not found at /data/medium-imagenet\\classes.txt\n",
      "HDF5 file not found at /data/medium-imagenet\\medium-imagenet-nmep-96.hdf5\n",
      "Please check the path and make sure the file exists.\n"
     ]
    }
   ],
   "source": [
    "# Path to the HDF5 dataset and class names file\n",
    "# Updated path to match the actual location on honeydew\n",
    "DATA_DIR = '/honey/nmep'\n",
    "HDF5_PATH = os.path.join(DATA_DIR, 'medium-imagenet-96.hdf5')  # Updated filename\n",
    "\n",
    "# Try to find class names file\n",
    "CLASS_NAMES_PATH = os.path.join(DATA_DIR, 'class_names.txt')\n",
    "\n",
    "# If the class_names.txt is not available, you can try these alternatives\n",
    "if not os.path.exists(CLASS_NAMES_PATH):\n",
    "    CLASS_NAMES_PATH = os.path.join(DATA_DIR, 'classnames.txt')\n",
    "    if not os.path.exists(CLASS_NAMES_PATH):\n",
    "        CLASS_NAMES_PATH = os.path.join(DATA_DIR, 'classes.txt')\n",
    "\n",
    "# Load class names\n",
    "try:\n",
    "    with open(CLASS_NAMES_PATH, 'r') as f:\n",
    "        class_names = [line.strip() for line in f.readlines()]\n",
    "    print(f\"Loaded {len(class_names)} class names\")\n",
    "    print(f\"First 5 classes: {class_names[:5]}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Class names file not found at {CLASS_NAMES_PATH}\")\n",
    "    # Try looking for class names in alternative locations\n",
    "    try:\n",
    "        alt_path = '/data/medium-imagenet/class_names.txt'\n",
    "        with open(alt_path, 'r') as f:\n",
    "            class_names = [line.strip() for line in f.readlines()]\n",
    "        print(f\"Loaded {len(class_names)} class names from {alt_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Falling back to generic class names\")\n",
    "        class_names = [f\"Class_{i}\" for i in range(200)]  # Fallback to generic names\n",
    "\n",
    "# Open the HDF5 file\n",
    "try:\n",
    "    h5_file = h5py.File(HDF5_PATH, 'r')\n",
    "    print(f\"Successfully opened HDF5 file: {HDF5_PATH}\")\n",
    "    print(f\"Available keys: {list(h5_file.keys())}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"HDF5 file not found at {HDF5_PATH}\")\n",
    "    print(\"Please check the path and make sure the file exists.\")\n",
    "    # You can try alternative paths here if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to recursively explore HDF5 structure\n",
    "def explore_h5_structure(item, indent=0):\n",
    "    if isinstance(item, h5py.Group):\n",
    "        print(' ' * indent + f\"Group: {item.name}\")\n",
    "        for key in item.keys():\n",
    "            explore_h5_structure(item[key], indent + 4)\n",
    "    elif isinstance(item, h5py.Dataset):\n",
    "        print(' ' * indent + f\"Dataset: {item.name}, Shape: {item.shape}, Dtype: {item.dtype}\")\n",
    "\n",
    "print(\"HDF5 File Structure:\")\n",
    "explore_h5_structure(h5_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a grid of images with their class names\n",
    "def display_images(images, labels, num_images=10, title=\"Dataset Samples\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(min(num_images, len(images))):\n",
    "        plt.subplot(int(np.ceil(num_images/4)), 4, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Class: {class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "\n",
    "# Function to display a grid of images using torchvision's make_grid\n",
    "def display_image_grid(images, labels, num_images=10, title=\"Dataset Samples Grid\"):\n",
    "    # Convert images to torch tensors and normalize\n",
    "    tensor_images = [torch.from_numpy(img.transpose(2, 0, 1)).float() / 255.0 for img in images[:num_images]]\n",
    "    grid = make_grid(tensor_images, nrow=5, padding=2)\n",
    "    \n",
    "    # Convert grid back to numpy for display\n",
    "    grid_np = grid.numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(grid_np)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Add class names below the image\n",
    "    class_text = \", \".join([class_names[labels[i]] for i in range(min(num_images, len(labels)))])\n",
    "    plt.figtext(0.5, 0.01, f\"Classes: {class_text}\", wrap=True, horizontalalignment='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize training samples\n",
    "try:\n",
    "    # Access train data and labels\n",
    "    train_data = h5_file['train_data']\n",
    "    train_labels = h5_file['train_labels']\n",
    "    \n",
    "    # Sample random indices\n",
    "    num_samples = 12\n",
    "    sample_indices = np.random.choice(len(train_labels), num_samples, replace=False)\n",
    "    \n",
    "    # Get the sampled images and labels\n",
    "    sample_images = [train_data[i] for i in sample_indices]\n",
    "    sample_labels = [train_labels[i] for i in sample_indices]\n",
    "    \n",
    "    # Display individual images\n",
    "    display_images(sample_images, sample_labels, num_samples, \"MediumImageNet Training Samples\")\n",
    "    \n",
    "    # Display as a grid\n",
    "    display_image_grid(sample_images, sample_labels, num_samples, \"MediumImageNet Training Samples Grid\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"Error accessing dataset: {e}\")\n",
    "    print(\"The HDF5 file structure might be different than expected.\")\n",
    "    print(f\"Available keys: {list(h5_file.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Validation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize validation samples\n",
    "try:\n",
    "    # Access validation data and labels\n",
    "    val_data = h5_file['val_data']\n",
    "    val_labels = h5_file['val_labels']\n",
    "    \n",
    "    # Sample random indices\n",
    "    num_samples = 12\n",
    "    sample_indices = np.random.choice(len(val_labels), num_samples, replace=False)\n",
    "    \n",
    "    # Get the sampled images and labels\n",
    "    sample_images = [val_data[i] for i in sample_indices]\n",
    "    sample_labels = [val_labels[i] for i in sample_indices]\n",
    "    \n",
    "    # Display individual images\n",
    "    display_images(sample_images, sample_labels, num_samples, \"MediumImageNet Validation Samples\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"Error accessing validation dataset: {e}\")\n",
    "    print(\"The validation set might be structured differently or not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Count occurrences of each class\n",
    "    train_labels_array = np.array(train_labels)\n",
    "    unique_classes, class_counts = np.unique(train_labels_array, return_counts=True)\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.bar(unique_classes, class_counts)\n",
    "    plt.xlabel('Class ID')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.title('Class Distribution in Training Set')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Total number of classes: {len(unique_classes)}\")\n",
    "    print(f\"Average samples per class: {np.mean(class_counts):.2f}\")\n",
    "    print(f\"Min samples in a class: {np.min(class_counts)}\")\n",
    "    print(f\"Max samples in a class: {np.max(class_counts)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing class distribution: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the HDF5 file\n",
    "h5_file.close()\n",
    "print(\"HDF5 file closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
